{
    "model_class": "Job",
    "id": "b7daf5aeee0c0274",
    "history_id": "d89039e64178a16c",
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/medaka_consensus/medaka_consensus/1.7.2+galaxy0",
    "state": "error",
    "exit_code": null,
    "create_time": "2025-02-20T01:14:47.478745",
    "update_time": "2025-02-20T01:14:59.079123",
    "galaxy_version": "24.1",
    "external_id": "gxy-c84lm",
    "handler": null,
    "job_runner_name": null,
    "command_line": "ln -s '/galaxy/server/database/objects/3/7/d/dataset_37d04748-dcb1-484e-b9ee-c4fcfb0b3f55.dat' alignment.bam && ln -s '/galaxy/server/database/objects/_metadata_files/8/9/d/metadata_89d081ca-a6a1-4acc-addc-1a9750053860.dat' alignment.bam.bai &&   medaka consensus --debug --threads ${GALAXY_SLOTS:-4} --batch_size 99 --chunk_len 9999 --chunk_ovlp 999 --model r941_min_fast_g303 --check_output --save_features --tag_keep_missing alignment.bam '/galaxy/server/database/objects/f/f/e/dataset_ffee5e46-d50a-4f06-804c-182545acc8b4.dat'  2>&1 | tee '/galaxy/server/database/objects/b/5/b/dataset_b5b6282b-9d51-4532-99f4-acc2bc5b8402.dat'",
    "user_email": "tests@fake.org",
    "command_version": null,
    "params": {
        "__input_ext": "\"input\"",
        "dbkey": "\"?\"",
        "chromInfo": "\"/cvmfs/data.galaxyproject.org/managed/len/ucsc/?.len\"",
        "out": "[\"result\", \"log\"]",
        "tag_keep_missing": "true",
        "tag_value": "\"\"",
        "tag_name": "\"\"",
        "RG": "\"\"",
        "save_features": "true",
        "check_output": "true",
        "chunk_ovlp": "\"999\"",
        "chunk_len": "\"9999\"",
        "regions_cond": "{\"__current_case__\": 0, \"regions_sel\": \"none\"}",
        "batch_size": "\"99\"",
        "model": "\"r941_min_fast_g303\""
    },
    "inputs": {
        "bam": {
            "id": "ed5afd197e8777e8",
            "src": "hda",
            "uuid": "37d04748-dcb1-484e-b9ee-c4fcfb0b3f55"
        }
    },
    "outputs": {
        "out_result": {
            "id": "81f3b4a3d3b94315",
            "src": "hda",
            "uuid": "ffee5e46-d50a-4f06-804c-182545acc8b4"
        },
        "out_log": {
            "id": "273b2399ce08c491",
            "src": "hda",
            "uuid": "b5b6282b-9d51-4532-99f4-acc2bc5b8402"
        }
    },
    "copied_from_job_id": null,
    "output_collections": {},
    "tool_stdout": "[01:14:53 - Predict] Reducing threads to 2, anymore is a waste.\n[01:14:53 - Predict] It looks like you are running medaka without a GPU and attempted to set a high number of threads. We have scaled this down to an optimal number. If you wish to improve performance please see https://nanoporetech.github.io/medaka/installation.html#improving-parallelism.\n[01:14:53 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n[01:14:53 - Predict] Processing region(s): ref:0-30\n[01:14:53 - Predict] Using model: /usr/local/lib/python3.8/site-packages/medaka/data/r941_min_fast_g303_model.hdf5.\n[01:14:53 - DataStre] Writing sample registry.\n[01:14:53 - Predict] Processing 1 long region(s) with batching.\n[01:14:53 - MdlStore] filepath /usr/local/lib/python3.8/site-packages/medaka/data/r941_min_fast_g303_model.hdf5\n2025-02-20 01:14:53.491740: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n[01:14:54 - BAMFile] Creating pool of 16 BAM file sets.\n[01:14:54 - DLoader] Sample-0: started\n[01:14:54 - Sampler] Initializing sampler for consensus of region ref:0-30.\n[01:14:54 - DLoader] Sample-1: started\n[01:14:54 - DLoader] Sample-1: finished\n[01:14:54 - DLoader] Initialised. Batch size:99. Workers:2. Cache:792\n[01:14:54 - PWorker] Running inference for 0.0M draft bases.\n[01:14:54 - Feature] Pileup counts do not span requested region, requested ref:0-30, received 0-9.\n[01:14:54 - Feature] Processed ref:0.0-9.0 (median depth 1.0)\n[01:14:54 - Feature] Pileup counts do not span requested region, requested ref:0-30, received 14-29.\n[01:14:54 - Feature] Processed ref:14.0-29.0 (median depth 1.0)\n[01:14:54 - Sampler] Took 0.04s to make features.\n[01:14:54 - Sampler] Region ref:0.0-9.0 (10 positions) is smaller than inference chunk length 9999, quarantining.\n[01:14:54 - Sampler] Region ref:14.0-29.0 (16 positions) is smaller than inference chunk length 9999, quarantining.\n[01:14:54 - DLoader] Sample-0: finished\n[01:14:54 - DLoader] Batches ready: 0. Samples ready: 0 (0.0 batches)\n[01:14:54 - DataStre] Writing sample registry.\n[01:14:54 - PWorker] Processed 0 batches\n[01:14:54 - PWorker] All done, 2 remainder regions.\n[01:14:54 - Predict] Processing 2 short region(s).\n[01:14:54 - MdlStore] filepath /usr/local/lib/python3.8/site-packages/medaka/data/r941_min_fast_g303_model.hdf5\n[01:14:54 - DLoader] Sample-0: started\n[01:14:54 - Sampler] Initializing sampler for consensus of region ref:0-10.\n[01:14:54 - DLoader] Sample-1: started\n[01:14:54 - Sampler] Initializing sampler for consensus of region ref:14-30.\n[01:14:54 - DLoader] Initialised. Batch size:1. Workers:2. Cache:8\n[01:14:54 - PWorker] Running inference for 0.0M draft bases.\n[01:14:54 - Feature] Processed ref:0.0-9.0 (median depth 1.0)\n[01:14:54 - Sampler] Took 0.01s to make features.\n[01:14:54 - Sampler] Pileup for ref:0.0-9.0 is of width 10\n[01:14:54 - DLoader] Sample-0: finished\n[01:14:54 - DLoader] Batches ready: 0. Samples ready: 0 (0.0 batches)\n[01:14:54 - Feature] Processed ref:14.0-29.0 (median depth 1.0)\n[01:14:54 - Sampler] Took 0.02s to make features.\n[01:14:54 - Sampler] Pileup for ref:14.0-29.0 is of width 16\n[01:14:54 - DLoader] Sample-1: finished\n[01:14:55 - DataStre] Loaded sample register.\n[01:14:55 - DataStre] Adding ref:0.0-9.0 to sample registry\n[01:14:55 - DLoader] Batches ready: 1. Samples ready: 0 (0.0 batches)\n[01:14:55 - DataStre] Adding ref:14.0-29.0 to sample registry\n[01:14:55 - DLoader] Batches ready: 0. Samples ready: 0 (0.0 batches)\n[01:14:55 - DataStre] Writing sample registry.\n[01:14:55 - PWorker] Processed 2 batches\n[01:14:55 - PWorker] All done, 0 remainder regions.\n[01:14:55 - Predict] Finished processing all regions.\n[01:14:55 - Predict] Validating and finalising output data.\n[01:14:55 - DataStre] Writing sample registry.\n[01:14:55 - DataStre] Created missing sample register.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n",
    "tool_stderr": "",
    "job_stdout": null,
    "job_stderr": null,
    "stdout": "[01:14:53 - Predict] Reducing threads to 2, anymore is a waste.\n[01:14:53 - Predict] It looks like you are running medaka without a GPU and attempted to set a high number of threads. We have scaled this down to an optimal number. If you wish to improve performance please see https://nanoporetech.github.io/medaka/installation.html#improving-parallelism.\n[01:14:53 - Predict] Setting tensorflow inter/intra-op threads to 2/1.\n[01:14:53 - Predict] Processing region(s): ref:0-30\n[01:14:53 - Predict] Using model: /usr/local/lib/python3.8/site-packages/medaka/data/r941_min_fast_g303_model.hdf5.\n[01:14:53 - DataStre] Writing sample registry.\n[01:14:53 - Predict] Processing 1 long region(s) with batching.\n[01:14:53 - MdlStore] filepath /usr/local/lib/python3.8/site-packages/medaka/data/r941_min_fast_g303_model.hdf5\n2025-02-20 01:14:53.491740: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n[01:14:54 - BAMFile] Creating pool of 16 BAM file sets.\n[01:14:54 - DLoader] Sample-0: started\n[01:14:54 - Sampler] Initializing sampler for consensus of region ref:0-30.\n[01:14:54 - DLoader] Sample-1: started\n[01:14:54 - DLoader] Sample-1: finished\n[01:14:54 - DLoader] Initialised. Batch size:99. Workers:2. Cache:792\n[01:14:54 - PWorker] Running inference for 0.0M draft bases.\n[01:14:54 - Feature] Pileup counts do not span requested region, requested ref:0-30, received 0-9.\n[01:14:54 - Feature] Processed ref:0.0-9.0 (median depth 1.0)\n[01:14:54 - Feature] Pileup counts do not span requested region, requested ref:0-30, received 14-29.\n[01:14:54 - Feature] Processed ref:14.0-29.0 (median depth 1.0)\n[01:14:54 - Sampler] Took 0.04s to make features.\n[01:14:54 - Sampler] Region ref:0.0-9.0 (10 positions) is smaller than inference chunk length 9999, quarantining.\n[01:14:54 - Sampler] Region ref:14.0-29.0 (16 positions) is smaller than inference chunk length 9999, quarantining.\n[01:14:54 - DLoader] Sample-0: finished\n[01:14:54 - DLoader] Batches ready: 0. Samples ready: 0 (0.0 batches)\n[01:14:54 - DataStre] Writing sample registry.\n[01:14:54 - PWorker] Processed 0 batches\n[01:14:54 - PWorker] All done, 2 remainder regions.\n[01:14:54 - Predict] Processing 2 short region(s).\n[01:14:54 - MdlStore] filepath /usr/local/lib/python3.8/site-packages/medaka/data/r941_min_fast_g303_model.hdf5\n[01:14:54 - DLoader] Sample-0: started\n[01:14:54 - Sampler] Initializing sampler for consensus of region ref:0-10.\n[01:14:54 - DLoader] Sample-1: started\n[01:14:54 - Sampler] Initializing sampler for consensus of region ref:14-30.\n[01:14:54 - DLoader] Initialised. Batch size:1. Workers:2. Cache:8\n[01:14:54 - PWorker] Running inference for 0.0M draft bases.\n[01:14:54 - Feature] Processed ref:0.0-9.0 (median depth 1.0)\n[01:14:54 - Sampler] Took 0.01s to make features.\n[01:14:54 - Sampler] Pileup for ref:0.0-9.0 is of width 10\n[01:14:54 - DLoader] Sample-0: finished\n[01:14:54 - DLoader] Batches ready: 0. Samples ready: 0 (0.0 batches)\n[01:14:54 - Feature] Processed ref:14.0-29.0 (median depth 1.0)\n[01:14:54 - Sampler] Took 0.02s to make features.\n[01:14:54 - Sampler] Pileup for ref:14.0-29.0 is of width 16\n[01:14:54 - DLoader] Sample-1: finished\n[01:14:55 - DataStre] Loaded sample register.\n[01:14:55 - DataStre] Adding ref:0.0-9.0 to sample registry\n[01:14:55 - DLoader] Batches ready: 1. Samples ready: 0 (0.0 batches)\n[01:14:55 - DataStre] Adding ref:14.0-29.0 to sample registry\n[01:14:55 - DLoader] Batches ready: 0. Samples ready: 0 (0.0 batches)\n[01:14:55 - DataStre] Writing sample registry.\n[01:14:55 - PWorker] Processed 2 batches\n[01:14:55 - PWorker] All done, 0 remainder regions.\n[01:14:55 - Predict] Finished processing all regions.\n[01:14:55 - Predict] Validating and finalising output data.\n[01:14:55 - DataStre] Writing sample registry.\n[01:14:55 - DataStre] Created missing sample register.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n[01:14:55 - BAMFile] Closing BAM file set.\n",
    "stderr": "",
    "job_messages": null,
    "dependencies": [],
    "job_metrics": []
}
